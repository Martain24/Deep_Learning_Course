{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendiendo el concepto de Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "**Definición**. Un *tensor* es una lista ordenada de números.\n",
    "\n",
    "**Ejemplo**. $x=(1,\\:0.4,\\:5)$ es un tensor de tamaño $3$, porque tiene $3$ componentes a lo largo de una única fila.\n",
    "\n",
    "Representación general de un vector: $x=(x_1,x_2,...,x_n)$. Fíjate que $x_i$ denota la componente $i$ de $x$.\n",
    "\n",
    "Se pueden tener tensores cuyos valores estén ordenados en varias filas (**matrices**):\n",
    "\n",
    "$$A = \\begin{bmatrix}2&1&4&\\\\\n",
    "0.5&6&2&\\\\\n",
    "-5&1.2&90\\\\\n",
    "-100&8&90\n",
    "\\end{bmatrix}\n",
    "\\:\\:\\:\\:\\:X=\\begin{bmatrix}x_{11}&x_{12}&...&x_{1n}\\\\\n",
    "x_{21}&x_{22}&...&x_{2n}\\\\\n",
    "...&...&...&...\\\\\n",
    "x_{m1}&x_{m2}&...&x_{mn} \n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$x_{ij}$ es la componente $j$ de la fila número $i$. \n",
    "\n",
    "La matriz tiene tamaño $m\\times n$ porque tiene $m$ filas de $n$ componentes cada una.\n",
    "\n",
    "La matriz tiene tamaño $m\\times n$ porque tiene $n$ columnas de $m$ componenetes cada una.\n",
    "\n",
    "**Observación**. Podemos tener tensores de tamaño $p\\times m\\times n$ formados por $p$ matrices de tamaño $m\\times n$.\n",
    "\n",
    "Decimos que un vector es un tensor de 1 dimensión; una matriz es un tensor de 2 dimensiones y un tensor de tamaño $p\\times m\\times n$ es de 3 dimensiones.\n",
    "\n",
    "Podemos tener tensores de tamaño $q\\times p\\times m\\times n$ y así hasta el infinito.\n",
    "\n",
    "De forma general, un tensor tendrá $k$ dimensiones si necesitamos $k$ números para especificar su tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librería PyTorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vector de todos los enteros entre 0 y 11\n",
    "x = torch.arange(0, 12)   # El \"end\" no se incluye \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder al número de componentes.\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder al tamaño del tensor\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder al número de dimensiones del tensor\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz a partir de los valores del tensor\n",
    "matrix = x.reshape(3, 4)\n",
    "matrix, matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "Una matriz de tamaño $m\\times n$ tiene exactamente $m\\cdot n$ componentes.\n",
    "\n",
    "Supón que tenemos un vector de $n$ componentes y queremos transformarlo en una matriz de $w$ filas.\n",
    "\n",
    "Entonces, para que quepan las $n$ componentes en la matriz necesariamente tendrá que haber $n/w$ columnas, porque $w\\cdot n/w=n$.\n",
    "\n",
    "Es decir, supón que tenemos un vector de $n$ componentes:\n",
    "- Si queremos transformarlo en una matriz de $w$ filas, necesariamente la matriz tendrá $n/w$ columnas.\n",
    "- Si queremos transformarlo en una matriz de $p$ columnas, necesariamente la matriz tendrá $n/p$ filas.\n",
    "\n",
    "Si ponemos $-1$, PyTorch calculará automáticamente el número de filas o de columnas que tiene que tener la nueva matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos que tenga 3 filas\n",
    "x.reshape(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos que tenga 6 columnas \n",
    "x.reshape(-1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos obtener una matriz columna\n",
    "x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ponemos un número que no es múltiplo de 12 obtenemos error\n",
    "num_filas = 7\n",
    "\n",
    "try:\n",
    "    print(x.reshape(num_filas, -1))\n",
    "except:\n",
    "    print(f\"No se puede hacer el reshape porque {num_filas} no es múltiplo de 12.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "Más funciones para generar tensores y viendo tensores de 3 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros((3, 2, 4))\n",
    "zeros, zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unos = torch.ones((3, 2, 2))\n",
    "unos, unos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Números aleatorios tomados de la distribución normal con media=0 y std=1\n",
    "normal_random = torch.randn(2, 3, 2, 2)\n",
    "normal_random, normal_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Números enteros aleatorios entre un máximo y un mínimo\n",
    "int_random = torch.randint(-100, 100, (5, 4))\n",
    "int_random, int_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos crear un tensor \"a mano\" pasandole una lista de Python\n",
    "torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de números enteros aleatorios.\n",
    "X = torch.randint(-20, 20, (4, 5))\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la primera y última fila.\n",
    "primera_fila = X[0]\n",
    "ultima_fila = X[-1]\n",
    "primera_fila, ultima_fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO devuelve tensor de misma dimensión que el original.\n",
    "X[0], X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tres_primeras_filas = X[0:3]\n",
    "tres_primeras_filas, tres_primeras_filas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Así podemos obtener una matriz fila.\n",
    "X[0:1], X[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué devuelve esto?\n",
    "## No poner nada = empezar desde el principio.\n",
    "X[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué devuelve esto? \n",
    "## No poner nada = ir hasta el final.\n",
    "X[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Y esto?\n",
    "X[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "- Vale, ya sabemos como acceder a elementos de la primera dimensión de nuestra matriz $X$.\n",
    "- ¿Cómo accedemos a las columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a una componente concreta de la matriz.\n",
    "fila = 0\n",
    "col = 3\n",
    "X[fila, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultima_columna = X[:, -1]\n",
    "\n",
    "# Nos devuelve un tensor con dimensión diferente al original.\n",
    "ultima_columna, ultima_columna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener en misma dimensión al original.\n",
    "X[:, -1:], X[:, -1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué devuelve esto de aquí?\n",
    "X[1:3, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensor de tres dimensiones de números enteros aleatorios.\n",
    "Y = torch.randint(-20, 20, (3, 4, 5))\n",
    "Y, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué obtendremos?\n",
    "print(Y[0], Y[0].shape)\n",
    "# ¿Cómo lo obtenemos con misma dimensión que el original?\n",
    "Y[0:1], Y[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué obtenemos?\n",
    "Y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué obtenemos?\n",
    "Y[0:1, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué obtenemos?\n",
    "Y[:, :, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué obtenemos con esto de aquí?\n",
    "Y[1:, 0:2, -3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tienes que practicar y practicar..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones con Tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dos matrices del mismo tamaño.\n",
    "X = torch.randint(-10, 10, (2, 3))\n",
    "Y = torch.randint(-10, 10, (2, 3))\n",
    "print(X, X.shape)\n",
    "print(\"\")\n",
    "print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar componente a componente\n",
    "X + Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicar componente a componente\n",
    "X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir componente a componente\n",
    "X/Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potenciación componente a componente\n",
    "X**Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "- También podemos juntar (stackear) tensores para formar otros nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randint(-10, 10, (2, 3))\n",
    "Y = torch.randint(-10, 10, (4, 3))\n",
    "print(X, X.shape)\n",
    "print(\"\")\n",
    "print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stackear verticalmente\n",
    "torch.vstack([X, Y, X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No podemos stackear horizontalmente pq no tienen mismo número de filas.\n",
    "try:\n",
    "    print(torch.hstack([X, Y]))\n",
    "except:\n",
    "    print(f\"Num filas X: {X.shape[0]}; Num filas Y: {Y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos que Y tenga el mismo número de filas que X con reshape\n",
    "Y = Y.reshape(X.shape[0], -1)\n",
    "print(Y, Y.shape)\n",
    "print(X, X.shape)\n",
    "\n",
    "# Concatenar horizontalmente\n",
    "torch.hstack([X,Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "- Podemos comparar tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[1, 2, 3],[5, 6, 7]])\n",
    "Y = torch.tensor([[4, 2, -10], [2, 6, 7]])\n",
    "print(X, X.shape)\n",
    "print(\"\")\n",
    "print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X >= Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X < Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_XY = (X == Y)\n",
    "equal_XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar todas componentes entre sí\n",
    "equal_XY.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar componentes columna por columna\n",
    "equal_XY.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar componentes fila por fila\n",
    "equal_XY.sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "- Aplicar funciones sobre las componentes de los tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randint(-10, 10, (2, 3))\n",
    "print(X, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El logaritmo neperiano es la inversa de exp\n",
    "X.exp().log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo de dato del tensor\n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por defecto, PyTorch está acostumbrado a manejar float32\n",
    "X.float().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesitas cambiar el tipo de dato de X para que funcione...\n",
    "X.float().mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.float().std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.float().var(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.,   8., -10.],\n",
      "        [ -2.,  -3.,   6.],\n",
      "        [ -9.,   5.,   3.],\n",
      "        [ -1.,  -8.,  -5.]]) torch.Size([4, 3])\n",
      "\n",
      "tensor([[ -4., -12.],\n",
      "        [ -1.,  -2.],\n",
      "        [  1., -14.],\n",
      "        [-11.,  -8.],\n",
      "        [ -3., -18.]]) torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randint(-10, 10, (4, 3)).float()\n",
    "Y = torch.randint(-20, 5, (5, 2)).float()\n",
    "print(X, X.shape)\n",
    "print(\"\")\n",
    "print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No podemos operar con tensores de diferente tamaño...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    X + Y \n",
    "except RuntimeError:\n",
    "    print(\"No podemos operar con tensores de diferente tamaño...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:20px\">\n",
    "\n",
    "- En ciertas condiciones se podrán realizar operaciones entre tensores de diferente tamaño.\n",
    "- Supón que tenemos los siguientes tensores:\n",
    "$$A=\\begin{bmatrix}1&2&3\\\\2&4&1\\end{bmatrix}\\:\\:\\:\\:\\:x=(3,2,1)$$\n",
    "- Queremos sumar $x$ en todas las filas de $A$.\n",
    "- Reglas de Broadcasting\n",
    "    - **Regla 1**: si los dos tensores difieren en el número de dimensiones, al tensor de menor número de dimensiones se le añade un uno en la izquierda. En nuestro ejemplo, el vector $x$, pasaría a ser una matriz fila, es decir, pasaría de tener tamaño $3$ a tamaño $1\\times 3$\n",
    "    $$x=(3,2,1)\\:\\:\\to\\:\\:x=\\begin{bmatrix}3&2&1\\end{bmatrix}$$\n",
    "\n",
    "    - **Regla 2**: Tenemos dos tensores con mismo número de dimensiones, pero con diferente tamaño. Si uno de ellos tiene un $1$ en una dimensión, entonces se expande dicho $1$ hasta que se iguale al valor que hay en el otro tensor. Como $x$ tiene tamaño $1\\times 3$, lo expandimos para que tenga tamaño $2\\times 3$.\n",
    "    $$x=\\begin{bmatrix}3&2&1\\end{bmatrix}\\:\\:\\to\\:\\:x=\\begin{bmatrix}3&2&1\\\\3&2&1\\end{bmatrix}$$\n",
    "\n",
    "    - **Regla 3**: si el tamaño sigue sin coindicir devuelve error. En nuestro ejemplo el tamaño sí conincide y, por tanto, se lleva a cabo la operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   8., -10.],\n",
       "         [ -2.,  -3.,   6.],\n",
       "         [ -9.,   5.,   3.],\n",
       "         [ -1.,  -8.,  -5.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.7500,  0.5000, -1.5000]), torch.Size([3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular media de las columnas\n",
    "mean_cols = X.mean(dim=0)\n",
    "mean_cols, mean_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.7500,  0.5000, -1.5000]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primer paso, poner un uno a la izquierda, para que el vector pase a ser una matriz fila.\n",
    "broad_mean_cols = mean_cols.reshape(1, -1)\n",
    "broad_mean_cols, broad_mean_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.7500,  0.5000, -1.5000],\n",
       "         [-2.7500,  0.5000, -1.5000],\n",
       "         [-2.7500,  0.5000, -1.5000],\n",
       "         [-2.7500,  0.5000, -1.5000]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segundo: hacer que el 1 en la primera dimensión se iguale al 4 de la matriz X\n",
    "## Stackeamos verticalmente el número de veces de X.shape[0]\n",
    "broad_mean_cols = torch.vstack([broad_mean_cols, \n",
    "                                broad_mean_cols, \n",
    "                                broad_mean_cols, \n",
    "                                broad_mean_cols])\n",
    "\n",
    "broad_mean_cols, broad_mean_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   8., -10.],\n",
       "        [ -2.,  -3.,   6.],\n",
       "        [ -9.,   5.,   3.],\n",
       "        [ -1.,  -8.,  -5.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7500,  7.5000, -8.5000],\n",
       "        [ 0.7500, -3.5000,  7.5000],\n",
       "        [-6.2500,  4.5000,  4.5000],\n",
       "        [ 1.7500, -8.5000, -3.5000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora realizamos la operación sin problema\n",
    "X - broad_mean_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7500,  0.5000, -1.5000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7500,  7.5000, -8.5000],\n",
       "        [ 0.7500, -3.5000,  7.5000],\n",
       "        [-6.2500,  4.5000,  4.5000],\n",
       "        [ 1.7500, -8.5000, -3.5000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo lo que hicimos ya lo hace PyTorch automáticamente\n",
    "X - mean_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   8., -10.],\n",
       "         [ -2.,  -3.,   6.],\n",
       "         [ -9.,   5.,   3.],\n",
       "         [ -1.,  -8.,  -5.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.3333,  0.3333, -0.3333, -4.6667]), torch.Size([4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rows = X.mean(dim=1)\n",
    "mean_rows, mean_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo realizar el broadcasting.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(X - mean_rows)\n",
    "except RuntimeError:\n",
    "    print(\"No se pudo realizar el broadcasting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3333],\n",
       "         [ 0.3333],\n",
       "         [-0.3333],\n",
       "         [-4.6667]]),\n",
       " torch.Size([4, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lo solucionamos convirtiendo mean_rows en una matriz columna\n",
    "mean_rows = mean_rows.reshape(-1, 1) \n",
    "mean_rows, mean_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   8., -10.],\n",
       "         [ -2.,  -3.,   6.],\n",
       "         [ -9.,   5.,   3.],\n",
       "         [ -1.,  -8.,  -5.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3333, -0.3333, -0.3333],\n",
       "        [ 0.3333,  0.3333,  0.3333],\n",
       "        [-0.3333, -0.3333, -0.3333],\n",
       "        [-4.6667, -4.6667, -4.6667]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Por broadcasting eso ocurrirá al realizar la operación.\n",
    "torch.hstack([mean_rows, mean_rows, mean_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  1.,   8., -10.],\n",
       "         [ -2.,  -3.,   6.],\n",
       "         [ -9.,   5.,   3.],\n",
       "         [ -1.,  -8.,  -5.]]),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3333],\n",
       "        [ 0.3333],\n",
       "        [-0.3333],\n",
       "        [-4.6667]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3333,  8.3333, -9.6667],\n",
       "        [-2.3333, -3.3333,  5.6667],\n",
       "        [-8.6667,  5.3333,  3.3333],\n",
       "        [ 3.6667, -3.3333, -0.3333]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A cada fila le restamos su media.\n",
    "X - mean_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
